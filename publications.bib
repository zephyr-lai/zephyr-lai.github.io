@INPROCEEDINGS{10008005,
  author={Lai, Zhiping and Kang, Xiaoyang and Wang, Hongbo and Zhang, Xueze and Zhang, Weiqi and Wang, Fuhao},
  booktitle={2022 IEEE International Joint Conference on Biometrics (IJCB)}, 
  title={Contrastive Domain Adaptation: A Self-Supervised Learning Framework for sEMG-Based Gesture Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  keywords={Human computer interaction;Electric potential;Biometrics (access control);Gesture recognition;Self-supervised learning;Electromyography;Calibration},
  doi={10.1109/IJCB54206.2022.10008005}}

  @InProceedings{10.1007/978-3-030-92238-2_3,
  author="Lai, Zhiping
  and Kang, Xiaoyang
  and Wang, Hongbo
  and Zhang, Weiqi
  and Zhang, Xueze
  and Gong, Peixian
  and Niu, Lan
  and Huang, Huijie",
  editor="Mantoro, Teddy
  and Lee, Minho
  and Ayu, Media Anugerah
  and Wong, Kok Wai
  and Hidayanto, Achmad Nizar",
  title="STCN-GR: Spatial-Temporal Convolutional Networks forÂ Surface-Electromyography-Based Gesture Recognition",
  booktitle="Neural Information Processing",
  year="2021",
  publisher="Springer International Publishing",
  address="Cham",
  pages="27--39",
  abstract="Gesture recognition using surface electromyography (sEMG) is the technical core of muscle-computer interface (MCI) in human-computer interaction (HCI), which aims to classify gestures according to signals obtained from human hands. Since sEMG signals are characterized by spatial relevancy and temporal nonstationarity, sEMG-based gesture recognition is a challenging task. Previous works attempt to model this structured information and extract spatial and temporal features, but the results are not satisfactory. To tackle this problem, we proposed spatial-temporal convolutional networks for sEMG-based gesture recognition (STCN-GR). In this paper, the concept of the sEMG graph is first proposed by us to represent sEMG data instead of image and vector sequence adopted by previous works, which provides a new perspective for the research of sEMG-based tasks, not just gesture recognition. Graph convolutional networks (GCNs) and temporal convolutional networks (TCNs) are used in STCN-GR to capture spatial-temporal information. Additionally, the connectivity of the graph can be adjusted adaptively in different layers of networks, which increases the flexibility of networks compared with the fixed graph structure used by original GCNs. On two high-density sEMG (HD-sEMG) datasets and a sparse armband dataset, STCN-GR outperforms previous works and achieves the state-of-the-art, which shows superior performance and powerful generalization ability.",
  isbn="978-3-030-92238-2"
  }
  
  