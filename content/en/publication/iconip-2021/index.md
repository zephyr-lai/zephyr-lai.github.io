---
title: 'STCN-GR: Spatial-Temporal Convolutional Networks forÂ Surface-Electromyography-Based
  Gesture Recognition'
authors:
- Zhiping Lai
- Xiaoyang Kang
- Hongbo Wang
- Weiqi Zhang
- Xueze Zhang
- Peixian Gong
- Lan Niu
- Huijie Huang
date: '2021-01-01'
publishDate: '2025-02-07T13:31:14.397377Z'
publication_types:
- paper-conference
publication: '*Neural Information Processing*'
abstract: Gesture recognition using surface electromyography (sEMG) is the technical
  core of muscle-computer interface (MCI) in human-computer interaction (HCI), which
  aims to classify gestures according to signals obtained from human hands. Since
  sEMG signals are characterized by spatial relevancy and temporal nonstationarity,
  sEMG-based gesture recognition is a challenging task. Previous works attempt to
  model this structured information and extract spatial and temporal features, but
  the results are not satisfactory. To tackle this problem, we proposed spatial-temporal
  convolutional networks for sEMG-based gesture recognition (STCN-GR). In this paper,
  the concept of the sEMG graph is first proposed by us to represent sEMG data instead
  of image and vector sequence adopted by previous works, which provides a new perspective
  for the research of sEMG-based tasks, not just gesture recognition. Graph convolutional
  networks (GCNs) and temporal convolutional networks (TCNs) are used in STCN-GR to
  capture spatial-temporal information. Additionally, the connectivity of the graph
  can be adjusted adaptively in different layers of networks, which increases the
  flexibility of networks compared with the fixed graph structure used by original
  GCNs. On two high-density sEMG (HD-sEMG) datasets and a sparse armband dataset,
  STCN-GR outperforms previous works and achieves the state-of-the-art, which shows
  superior performance and powerful generalization ability.
weight: 20
---
